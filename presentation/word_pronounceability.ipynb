{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our Goal:\n",
    "Be able to determine, given a consecutive string of letters, if it is pronounceable by english-speaking people. \n",
    "\n",
    "\n",
    "# Problem statement\n",
    "- We want to improve at classifying \"words\" as being pronounceable or not\n",
    "- We will measure our progress by the percentage of words correctly classified\n",
    "- based on our database of a literal dictionary and randomly-ish generated non-pronounceable words\n",
    "\n",
    "\n",
    "# Methodology\n",
    "Train several different models on our dataset, trying to teach them what \"pronounceable\" words look like\n",
    "This will include a manually designed heuristic and different ML models\n",
    "\n",
    "## Input Formulation (ML Models)\n",
    "We need to transform words into input vectors, since we need to have quantifiable data. \n",
    "\n",
    "Since we need to store the bigrams of the words, and we care about order, we decided to define the features of our vectors as a list of all possible bigrams within the english alphabet. This results in a 26*26 = 676-dimensional space. We will not be able to encode the order of the bigrams, because any meaningful encoding of this would result in either difficulty plotting the data or skewed data. For example, if the first bigram in the word was given a value of 1, the second was given a value of 2, et cetera, then the feature vectors of longer words would become further and further from the origin in the dimensions of their later bigrams.\n",
    "\n",
    "If our model seems to be less accurate than we would like, we will experiment with finding a way to encode the order.\n",
    "\n",
    "\n",
    "### For example, \n",
    "Our feature vector will take the following shape:\n",
    "`[\"aa\": int, \"ab\": int, \"ac\": int, \"ad\": int .. \"zz\": int]`\n",
    "\n",
    "So for a word like \"abba\", which contains the bigrams `[\"ab\", \"bb\", \"ba\"]`,\n",
    "Our feature vector would be:\n",
    "\n",
    "`[\"aa\": 0, \"ab\": 1, \"ac\": 0 ... \"ba\": 1, \"bb\": 1, \"bc\": 0 ...]`\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, sys\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def update_progress(progress, label: str = \"\"):\n",
    "    bar_length = 20\n",
    "    if isinstance(progress, int):\n",
    "        progress = float(progress)\n",
    "    if not isinstance(progress, float):\n",
    "        progress = 0\n",
    "    if progress < 0:\n",
    "        progress = 0\n",
    "    if progress >= 1:\n",
    "        progress = 1\n",
    "\n",
    "    block = int(round(bar_length * progress, 0))\n",
    "\n",
    "    clear_output(wait = True)\n",
    "    text = label+\"\\nProgress: [{0}] {1:.1f}%\".format( \"#\" * block + \"-\" * (bar_length - block), progress * 100)\n",
    "    print(text)\n",
    "\n",
    "\n",
    "def get_bigrams(word:str) -> list:\n",
    "    return [i+j for i, j in \\\n",
    "            zip(word, word[1:])]\n",
    "\n",
    "\n",
    "import functools\n",
    "def foldl(func, xs, acc):\n",
    "    return functools.reduce(func, xs, acc)\n",
    "\n",
    "def is_probability(input):\n",
    "    return isinstance(input, float) and \\\n",
    "        input >= 0 and \\\n",
    "            input <= 1\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Static variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_likelihood = {}\n",
    "accuracy_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorization Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations_with_replacement\n",
    "import string\n",
    "\n",
    "\n",
    "def generate_feature_vector(input):\n",
    "    # we will be outsourcing this to a c subprocess to increase perf\n",
    "    if(\"str\" in str(type(input))):\n",
    "        return generate_feature_vector(get_bigrams(input))\n",
    "    elif(\"list\" in str(type(input))):\n",
    "        feature_vector = {\n",
    "            str(bigram) : 1 if (str(bigram[0])+str(bigram[1])) in input else 0 \\\n",
    "                for bigram in \\\n",
    "                    [i+j for i in string.ascii_lowercase for j in string.ascii_lowercase]\n",
    "        }\n",
    "        return feature_vector\n",
    "    else:\n",
    "        print(input)\n",
    "        raise TypeError(f\"Requires either 'str' or List[str] as input for generate_feature_vector(), found {type(input)}.\")\n",
    "        \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "def get_vectors_for_series(data: pd.Series, label: str):\n",
    "    vectors = []\n",
    "    length = len(data)\n",
    "    for i in range(length):\n",
    "        word = data.loc[i]\n",
    "        if i % 5 == 0 or i == length:\n",
    "            update_progress(i / length, label=label)\n",
    "        vectors.append(np.asarray(list(generate_feature_vector(get_bigrams(word)).values())))\n",
    "    return pd.Series(vectors)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Creation Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "import typing\n",
    "import math\n",
    "\n",
    "def get_n_pronounceable_words(n: int) -> typing.Set[str]:\n",
    "    data_path = os.path.normpath(os.path.join(os.path.dirname(os.path.abspath(\"word_pronounceability.ipynb\")), '..', 'unigram_freq.csv'))\n",
    "    dataframe = pd.read_csv(data_path)\n",
    "    dataframe = dataframe[dataframe.word.str.len() >= 3]\n",
    "    dataframe = dataframe.set_axis(range(0, dataframe.shape[0]), axis=0)\n",
    "    \n",
    "    sample_size_n = dataframe.sample(n = n)\n",
    "    return set(sample_size_n[\"word\"])\n",
    "\n",
    "def get_n_unpronounceable_words(n: int) -> typing.Set[str]:\n",
    "    def norm(vector:list):\n",
    "        return math.sqrt(sum([i*i for i in vector]))\n",
    "        \n",
    "    words: typing.Set[str] = set()\n",
    "    while len(words) < n:\n",
    "        possible_word = ''.join(random.choice(string.ascii_lowercase) for _ in range(random.choice(list(range(3,15)))))\n",
    "\n",
    "        violates_q_u_rule = \"q\" in possible_word and \"qu\" not in possible_word\n",
    "\n",
    "        num_consecutive_consonants = foldl(lambda x, y: x+1 if y not in list(\"aeiouy\") else 0, possible_word, 0)\n",
    "        \n",
    "        contains_no_vowels = num_consecutive_consonants == len(possible_word)\n",
    "\n",
    "        incorrectness_vector = [0.8*(1 if contains_no_vowels else 0), 0.4*(num_consecutive_consonants/4)]\n",
    "        incorrectness_vector.append(0.8*(norm(incorrectness_vector)) if violates_q_u_rule else norm(incorrectness_vector))\n",
    "        # ADJUST IF THE WORDS ARE TOO PRONOUNCEABLE\n",
    "        if norm(incorrectness_vector) > 0.7 and possible_word not in words:\n",
    "            words.add(possible_word)\n",
    "    return words\n",
    "\n",
    "\n",
    "def get_dataset(size: int) -> pd.DataFrame:\n",
    "    \"\"\"Generates a dataset of \"words.\" Half are pronounceable, half are not\n",
    "\n",
    "    Args:\n",
    "        size (int): Size of each half of the dataset (pronounceable / unpronounceable)\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: dataframe with two columns: \"word\" and \"is_pronounceable\" with `2*size` rows.\n",
    "    \"\"\"\n",
    "    data_set = pd.DataFrame(list(get_n_pronounceable_words(size)) + (list((get_n_unpronounceable_words(size)))), columns=[\"word\"])\n",
    "    data_set[\"is_pronounceable\"] = data_set.index < size\n",
    "    return data_set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heuristic Model\n",
    "Our initial hypothesis was that the pronounceability of a word correlated very strongly with it's *likelihood*. This is to say, if it is statistically probable that a sequence of letters could make a word, it is also statistically probable that it can be pronounced. This is not without caveats, however: especially because we have idiomatically accepted brand names like \"Exxon\" which contain strings of letters which no (or at least very few) dictionary words contain. This fact would drive down the likelihood that these such strings of letters would appear, yet we can pronounce them perfectly fine. However, despite these caveats, we feel that this is a reasonable heuristic.\n",
    "\n",
    "## Heuristic Model Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "from statistics import mean\n",
    "def pronounceable_score_heuristic(letters: str) -> float:\n",
    "    \"\"\" Generates a numerical score representing the likelihood that a word is pronounceable.\n",
    "\n",
    "    Args:\n",
    "        letters (str): string of length 2 (bigram) containing only alphabetical characters to check our dataset for occurrences of\n",
    "\n",
    "    Returns:\n",
    "        float: a score representing the likelihood that we can pronounce this string of letters. 0.5 is generally pronounceable, 0.2 is not.\n",
    "    \"\"\"\n",
    "    assert len(letters) == 2\n",
    "    # if we have already checked this bigram, it'll be in our letter_likelihood dictionary, we can return it\n",
    "    if letters in letter_likelihood:\n",
    "        return letter_likelihood[letters]\n",
    "\n",
    "    # otherwise,\n",
    "    # check dataset for occurrences of [letters].\n",
    "    data = list(get_n_pronounceable_words(9000))\n",
    "    proportion = dict(in_line=0, not_in=0)\n",
    "    for word in data:\n",
    "        proportion['in_line' if letters in word else \"not_in\"] += 1\n",
    "    proportion['in_line'] -= 1 if (not proportion['in_line'] > 0) else 0\n",
    "    # if the set of letters is never found, then it almost certainly can't be pronounced, or possibly is simply not in our dataset.\n",
    "    # return the amount of times it was found divided by the total lines in the file (multiply by 10 to trim leading zeroes)\n",
    "    letter_likelihood[letters] = (proportion['in_line'] / sum([proportion[key] for key in proportion]))*10 \n",
    "    return letter_likelihood[letters]\n",
    "def is_pronounceable_heuristic(word: str) -> bool:\n",
    "    # Threshold of 0 gives 50% accuracy, anything above  0.5 gives 50% accuracy\n",
    "    THRESHOLD = 0.1\n",
    "\n",
    "    # turns word into list of bigrams into their likelihood of showing up in our dataset\n",
    "    # \"hello\" ->  [\"he\", \"el\", \"ll\", \"lo\"] -> [0.45..., 0.62..., 0.57..., 0.44...]\n",
    "    average_score = mean([pronounceable_score_heuristic(bigram) for bigram in get_bigrams(word)])\n",
    "\n",
    "    # if the average pronounceability score is too low, we assume it isn't pronounceable.\n",
    "    return average_score >= THRESHOLD\n",
    "\n",
    "\n",
    "# this function allows for more concise and readable code in our test flow.\n",
    "# uses a contextlib contextmanager to implement __enter__ and __exit__ for our function so we can use it in 'with' statements.\n",
    "@contextmanager\n",
    "def heuristic_function():\n",
    "    function = is_pronounceable_heuristic\n",
    "    try:\n",
    "        yield function\n",
    "    finally:\n",
    "        pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have defined our heuristic model, we can test it on a large segment of data and check to see if it appropriately classifies incoming data.\n",
    "\n",
    "\n",
    "## Heuristic Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_heuristic = False\n",
    "with heuristic_function() as is_pronounceable:\n",
    "    if not skip_heuristic:\n",
    "        test_data = pd.DataFrame(columns=[\"word\", \"is_pronounceable\"])\n",
    "        pronounceable_data = pd.DataFrame(columns=[\"word\"], data=pd.Series(list(get_n_pronounceable_words(1000))))\n",
    "        pronounceable_data[\"is_pronounceable\"] = True\n",
    "\n",
    "        unpronounceable_data = pd.DataFrame(columns=[\"word\"], data=pd.Series(list(get_n_unpronounceable_words(1000))))\n",
    "        unpronounceable_data[\"is_pronounceable\"] = False\n",
    "\n",
    "        test_data = pd.concat(objs=[pronounceable_data, unpronounceable_data])\n",
    "        scoring = dict(right= 0, total = 0)\n",
    "        for idx, row in test_data.iterrows():\n",
    "            update_progress(scoring[\"total\"] / test_data.shape[0])\n",
    "            if(is_pronounceable(row[\"word\"]) == row[\"is_pronounceable\"]):\n",
    "                # print(\"guessed correctly that \" + row[\"word\"] + \" is \" + (\"not \" if not row[\"is_pronounceable\"] else \"\") + \"pronounceable\")\n",
    "                scoring[\"right\"] += 1\n",
    "            # else:\n",
    "            #     print(\"guessed incorrectly that \" + row[\"word\"] + \" is \" + (\"\" if not row[\"is_pronounceable\"] else \"not \") + \"pronounceable\")\n",
    "            scoring[\"total\"] += 1\n",
    "        \n",
    "        accuracy_dict[\"Heuristic Model\"] = (scoring[\"right\"] / scoring[\"total\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## ML Code\n",
    "\n",
    "\n",
    " Now that we have the ability to turn words into vectors (through one-hot encoding), we can begin to train models on these vectors. Since we are looking for a one-vs-one classification, we can use, for example:\n",
    " 1. Naive Bayes\n",
    " 2. K Nearest Neighbors\n",
    " 3. Semi-supervised learning\n",
    " 4. Support Vector Machines\n",
    " 5. essentially any model in the scikit-learn `multiclass` package\n",
    "\n",
    " ### Training / Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [####################] 99.9%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "size = 3000 # size of each half of the dataset\n",
    "data_set = get_dataset(size)\n",
    "\n",
    "X_vectors = list(get_vectors_for_series(data_set[\"word\"], label=\"\"))\n",
    "\n",
    "# Convert from list of np arrays to single 2darray\n",
    "X = np.array([x for x in X_vectors])\n",
    "y = np.array([np.array(1 if i else 0) for i in data_set[\"is_pronounceable\"]])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, list(y), test_size=0.25, random_state=7)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "naive_bayes_model = BernoulliNB()\n",
    "naive_bayes_model.fit(X_train, y_train)\n",
    "\n",
    "accuracy_dict[\"Naive Bayes\"] = naive_bayes_model.score(X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "n_neighbors = 10\n",
    "knn_model = KNeighborsClassifier(n_neighbors=n_neighbors).fit(X_train, y_train)\n",
    "accuracy_dict[f\"K-Nearest-Neighbors ({n_neighbors} neighbors)\"] = knn_model.score(X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semi-supervised Learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [####################] 100.0%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.semi_supervised import LabelPropagation\n",
    "\n",
    "# get a \"LOT\" of extra data, and label it as -1\n",
    "\n",
    "words_unlabeled = pd.Series(list(get_n_pronounceable_words(4500).union(get_n_unpronounceable_words(4500))))\n",
    "X_unlabeled = np.array([i for i in list(get_vectors_for_series(words_unlabeled))])\n",
    "y_unlabeled = np.array([-1 for _ in X_unlabeled])\n",
    "\n",
    "\n",
    "X_mixed = np.concatenate((X_train, X_unlabeled), axis=0)\n",
    "\n",
    "y_mixed = np.concatenate((y_train, y_unlabeled), axis=0)\n",
    "\n",
    "\n",
    "semi_supervised_model = LabelPropagation().fit(X_mixed, y_mixed)\n",
    "\n",
    "\n",
    "accuracy_dict[\"Semi Supervised (Label Propagation)\"] = (semi_supervised_model.score(X_test, y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import NuSVC\n",
    "\n",
    "#TODO Tune parameters\n",
    "svc_model = NuSVC().fit(X_train, y_train)\n",
    "accuracy_dict[\"Support Vector Machine (NuSVC)\"]= (svc_model.score(X_test, y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#  TODO Tune parameters:\n",
    "nn_model = MLPClassifier(learning_rate = \"invscaling\").fit(X_train, y_train)\n",
    "accuracy_dict[\"Neural Network (Multi-Layer Perceptron)\"] = (nn_model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats for most recent run:\n",
      "Accuracy for Heuristic Model: 88.7%\n"
     ]
    }
   ],
   "source": [
    "print(\"Stats for most recent run:\")\n",
    "for model in accuracy_dict:\n",
    "    print(f\"Accuracy for {model}: {str(accuracy_dict[model]*100)[:5]}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 30/30\n",
      "Progress: [####################] 99.8%\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "# increase sample size by increasing n\n",
    "best_model = NuSVC()\n",
    "n = 30\n",
    "for i in range(n):\n",
    "    size = 1500 # size of each half of the dataset\n",
    "    data_set = get_dataset(size)\n",
    "\n",
    "    X_vectors = list(get_vectors_for_series(data_set[\"word\"], label=f\"Iteration {i+1}/{n}\"))\n",
    "\n",
    "    # Convert from list of np arrays to single 2darray\n",
    "    X = np.array([x for x in X_vectors])\n",
    "    y = np.array([np.array(1 if i else 0) for i in data_set[\"is_pronounceable\"]])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, list(y), test_size=0.25, random_state=7)\n",
    "    model = best_model.fit(X_train, y_train)\n",
    "    accuracies.append(svc_model.score(X_test, y_test))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The t-statistic is 66.922 and the p-value is 0.000.\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "assert len(accuracies) == 30\n",
    "# all values in accuracies list are probabilities\n",
    "assert max([0 if is_probability(sample) else 1 for sample in accuracies]) == 0\n",
    "assert is_probability(accuracy_dict[\"Heuristic Model\"])\n",
    "\n",
    "one_sample = stats.ttest_1samp(accuracies, accuracy_dict[\"Heuristic Model\"])\n",
    "print(\"The t-statistic is %.3f and the p-value is %.3f.\" % one_sample)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8a94588eda9d64d9e9a351ab8144e55b1fabf5113b54e67dd26a8c27df0381b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
